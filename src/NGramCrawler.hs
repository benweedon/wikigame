module NGramCrawler
    ( NGramCrawler
    , makeCrawler
    , nextPage
    ) where

import Crawler (Crawler, makeCrawler, nextPage)
import NGramModel (NGramModel, makeModel, scoreText)
import Page (Page(..), fullUrl, scrapeTitle, scrapeLinks, scrapeContentText, convertMaybe)

import Control.Concurrent (forkIO)
import Control.Concurrent.MVar (MVar, newEmptyMVar, putMVar, takeMVar)
import Data.Foldable (maximumBy)
import Data.List (sortBy)
import Data.Map.Strict (Map)
import qualified Data.Map.Strict as M (empty, insert, lookup)
import Data.Set (Set)
import qualified Data.Set as S (empty, insert, notMember)
import Text.HTML.Scalpel (URL, scrapeURL)

n :: Word
n = 1

maxTopLinks :: Word
maxTopLinks = 5

maxIndexedModels :: Word
maxIndexedModels = 10

infinity :: Double
infinity = 1 / 0

data PageData = PageData
    { pd_page :: Page
    , pd_linkScores :: [((String, URL), Double)]
    }

data NGramCrawler = NGramCrawler
    { ngc_startUrl :: URL
    , ngc_endUrl :: URL
    , ngc_pageData :: Maybe PageData
    , ngc_endUrlModel :: NGramModel
    , ngc_indexedModels :: [NGramModel]
    , ngc_urlScores :: Map URL Double
    , ngc_visitedUrls :: Set URL
    }

instance Crawler NGramCrawler where
    makeCrawler startUrl endUrl = do
        endUrlText <- getUrlContentText endUrl
        return $ NGramCrawler
            { ngc_startUrl = startUrl
            , ngc_endUrl = endUrl
            , ngc_pageData = Nothing
            , ngc_endUrlModel = makeModel n True endUrlText
            , ngc_indexedModels = map (flip (`makeModel` False) endUrlText) [1..10]
            , ngc_urlScores = M.empty
            , ngc_visitedUrls = S.empty
            }

    nextPage crawler =
        case ngc_pageData crawler of
            Just pageData -> do
                (nextPageData, newCrawlerWithoutPageData) <- getNextPageData pageData crawler
                let newCrawler = newCrawlerWithoutPageData { ngc_pageData = Just nextPageData }
                let newPage = pd_page nextPageData
                return (newCrawler, newPage)
            Nothing -> do
                (pageData, newCrawlerWithoutPageData) <- getPageData Nothing (ngc_startUrl crawler) crawler
                let newCrawler = newCrawlerWithoutPageData { ngc_pageData = Just pageData }
                let newPage = pd_page pageData
                return (newCrawler, newPage)

getNextPageData :: PageData -> NGramCrawler -> IO (PageData, NGramCrawler)
getNextPageData pageData crawler = do
    let (sourceLinkText, url) = getNextPage pageData
    getPageData (Just sourceLinkText) url crawler

getPageData :: Maybe String -> URL -> NGramCrawler -> IO (PageData, NGramCrawler)
getPageData sourceLinkText url crawler = do
    let scraper = do
            title <- scrapeTitle
            links <- scrapeLinks
            return (title, links)
    (title, links) <- scrapeURL (fullUrl url) scraper >>= convertMaybe url

    let linkNameScores = map (scoreLinkName crawler) links
    let sortedLinkNameScores = sortBy (flip compareLinkScores) linkNameScores
    let sortedLinks = map fst sortedLinkNameScores
    let filteredLinks = filter ((`S.notMember` ngc_visitedUrls crawler) . snd) sortedLinks
    let topLinks = take (fromIntegral maxTopLinks) filteredLinks

    let ioList = map (scoreLink crawler) topLinks
    let mVarIoList = map ioToMVar ioList
    mVars <- listIoToIoList mVarIoList
    linkScores <- listIoToIoList $ map takeMVar mVars

    let newUrlScores = foldr
            (\((_, u), score) m -> M.insert u score m)
            (ngc_urlScores crawler)
            linkScores
    let newVisitedUrls = S.insert url (ngc_visitedUrls crawler)

    let page = Page { p_title = title, p_url = url, p_sourceLinkText = sourceLinkText }
    return
        ( PageData { pd_page = page, pd_linkScores = linkScores }
        , crawler
            { ngc_urlScores = newUrlScores
            , ngc_visitedUrls = newVisitedUrls
            }
        )

getNextPage :: PageData -> (String, URL)
getNextPage pageData =
    link
    where
        scores = pd_linkScores pageData
        maxScoreLink = maximumBy compareLinkScores scores
        (link, _) = maxScoreLink

getUrlContentText :: URL -> IO String
getUrlContentText url =
    scrapeURL (fullUrl url) scrapeContentText >>= convertMaybe url

scoreLinkName :: NGramCrawler -> (String, URL) -> ((String, URL), Double)
scoreLinkName crawler (sourceLinkText, url)
    | url == ngc_endUrl crawler = ((sourceLinkText, url), infinity)
    | numWords <= maxIndexedModels = ((sourceLinkText, url), scoreText model sourceLinkText)
    | otherwise = ((sourceLinkText, url), 0)
    where
        numWords = fromIntegral $ length $ words sourceLinkText
        model = ngc_indexedModels crawler !! fromIntegral (numWords - 1)

scoreLink :: NGramCrawler -> (String, URL) -> IO ((String, URL), Double)
scoreLink crawler (sourceLinkText, url) =
    case M.lookup url $ ngc_urlScores crawler of
        Just score -> return ((sourceLinkText, url), score)
        Nothing ->
            scrapeURL (fullUrl url) scraper >>= convertMaybe url
            where
                model = ngc_endUrlModel crawler
                scraper = do
                    contentText <- scrapeContentText
                    return ((sourceLinkText, url), scoreText model contentText)

compareLinkScores :: ((String, URL), Double) -> ((String, URL), Double) -> Ordering
compareLinkScores (_, score1) (_, score2) = compare score1 score2

ioToMVar :: IO a -> IO (MVar a)
ioToMVar io = do
    mVar <- newEmptyMVar
    let thread = do
            result <- io
            putMVar mVar result
    _ <- forkIO thread
    return mVar

listIoToIoList :: [IO a] -> IO [a]
listIoToIoList (first : rest) = do
    firstUnwrapped <- first
    restUnwrapped <- listIoToIoList rest
    return $ firstUnwrapped : restUnwrapped
listIoToIoList [] = return []
